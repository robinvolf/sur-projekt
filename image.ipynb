{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049123e7-2875-49b2-887c-94597c4edb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import *\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62134c94-425d-4eec-842a-458f1b2a543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # Mozno viac safe to use ako cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef957f6-5f4e-46fd-954f-f0e66dcbfdb3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def load_sample_images(base_path, num_images=5):\n",
    "#     # ['train', 'dev'] - asi dev teraz netreba\n",
    "#     for folder_type in ['train', 'dev']:  # Process both train and dev folders\n",
    "#         folder_path = base_path / folder_type\n",
    "#         print(f\"\\nProcessing {folder_type} folder:\")\n",
    "        \n",
    "#         if not folder_path.exists():\n",
    "#             print(f\"Folder {folder_type} not found!\")\n",
    "#             continue\n",
    "            \n",
    "#         # Process folders 1-31\n",
    "#         for i in range(1, 32):  # range(1, 32) gives 1-31\n",
    "#             subfolder = folder_path / str(i)\n",
    "            \n",
    "#             if not subfolder.exists():\n",
    "#                 print(f\"Subfolder {i} not found in {folder_type}\")\n",
    "#                 continue\n",
    "                \n",
    "#             # Get all image files (assuming common image extensions)\n",
    "#             image_files = list(subfolder.glob('*.png'))\n",
    "            \n",
    "#             if not image_files:\n",
    "#                 print(f\"No images found in {subfolder}\")\n",
    "#                 continue\n",
    "                \n",
    "#             # Select up to num_images randomly (or all if there are fewer)\n",
    "#             selected_images = random.sample(image_files, min(num_images, len(image_files)))\n",
    "            \n",
    "#             print(f\"\\nFolder {i}: Loading {len(selected_images)} images\")\n",
    "#             for img_path in selected_images:\n",
    "#                 # Load with cv2 and convert to RGB\n",
    "#                 img = cv2.imread(str(img_path))\n",
    "#                 img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "#                 # You would typically process the image here\n",
    "#                 print(f\"Loaded {img_path.name} - Shape: {img_rgb.shape}\")\n",
    "\n",
    "# # Usage\n",
    "# base_directory = Path('.')  # Current directory or specify your base path\n",
    "# load_sample_images(base_directory, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eab01fc-e31a-475c-b001-68f4bda0c666",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train folder:\n",
      "\n",
      "Folder 1: Loading 6 images\n",
      "Loaded f401_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f401_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f401_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f401_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f401_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f401_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 2: Loading 6 images\n",
      "Loaded f402_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f402_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f402_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f402_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f402_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f402_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 3: Loading 6 images\n",
      "Loaded f403_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f403_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f403_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f403_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f403_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f403_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 4: Loading 6 images\n",
      "Loaded f404_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f404_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f404_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f404_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f404_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f404_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 5: Loading 6 images\n",
      "Loaded f405_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f405_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f405_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f405_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f405_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f405_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 6: Loading 6 images\n",
      "Loaded f406_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f406_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f406_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f406_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f406_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f406_03_r06_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 7: Loading 6 images\n",
      "Loaded f407_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f407_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f407_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f407_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f407_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f407_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 8: Loading 6 images\n",
      "Loaded f408_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f408_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f408_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f408_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f408_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f408_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 9: Loading 6 images\n",
      "Loaded f409_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f409_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f409_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f409_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f409_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f409_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 10: Loading 6 images\n",
      "Loaded f410_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f410_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f410_02_f21_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f410_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f410_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f410_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 11: Loading 6 images\n",
      "Loaded f411_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f411_01_r06_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f411_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f411_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f411_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f411_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 12: Loading 6 images\n",
      "Loaded f412_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f412_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f412_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f412_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f412_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f412_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 13: Loading 6 images\n",
      "Loaded f413_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f413_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f413_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f413_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f413_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f413_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 14: Loading 6 images\n",
      "Loaded f415_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f415_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f415_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f415_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f415_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f415_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 15: Loading 6 images\n",
      "Loaded f433_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f433_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f433_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f433_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f433_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f433_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 16: Loading 6 images\n",
      "Loaded m414_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m414_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m414_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m414_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m414_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m414_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 17: Loading 6 images\n",
      "Loaded m417_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m417_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m417_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m417_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m417_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m417_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 18: Loading 6 images\n",
      "Loaded m419_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m419_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m419_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m419_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m419_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m419_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 19: Loading 6 images\n",
      "Loaded m420_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m420_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m420_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m420_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m420_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m420_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 20: Loading 6 images\n",
      "Loaded m421_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m421_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m421_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m421_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m421_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m421_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 21: Loading 6 images\n",
      "Loaded m422_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m422_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m422_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m422_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m422_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m422_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 22: Loading 6 images\n",
      "Loaded m423_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m423_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m423_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m423_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m423_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m423_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 23: Loading 6 images\n",
      "Loaded m424_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m424_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m424_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m424_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m424_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m424_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 24: Loading 6 images\n",
      "Loaded m425_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m425_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m425_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m425_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m425_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m425_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 25: Loading 6 images\n",
      "Loaded m426_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m426_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m426_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m426_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m426_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m426_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 26: Loading 6 images\n",
      "Loaded m427_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m427_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m427_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m427_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m427_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m427_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 27: Loading 6 images\n",
      "Loaded m428_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m428_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m428_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m428_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m428_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m428_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 28: Loading 6 images\n",
      "Loaded m429_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m429_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m429_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m429_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m429_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m429_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 29: Loading 6 images\n",
      "Loaded m430_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m430_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m430_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m430_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m430_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m430_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 30: Loading 6 images\n",
      "Loaded m431_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m431_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m431_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m431_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m431_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m431_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 31: Loading 6 images\n",
      "Loaded m432_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m432_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m432_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m432_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m432_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded m432_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n"
     ]
    }
   ],
   "source": [
    "def load_images_from_folders(base_path):\n",
    "    folder_path = base_path / 'train'\n",
    "    print(f\"Processing train folder:\")\n",
    "    \n",
    "    if not folder_path.exists():\n",
    "        print(\"Train folder not found!\")\n",
    "        return\n",
    "    \n",
    "    # Process folders 1-31\n",
    "    for folder_num in range(1, 32):\n",
    "        subfolder = folder_path / str(folder_num)\n",
    "        \n",
    "        if not subfolder.exists():\n",
    "            print(f\"Subfolder {folder_num} not found\")\n",
    "            continue\n",
    "            \n",
    "        # Get all PNG files\n",
    "        image_files = sorted(subfolder.glob('*.png'))\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"No PNG images found in {subfolder}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nFolder {folder_num}: Loading {len(image_files)} images\")\n",
    "        for img_path in image_files:\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                print(f\"Loaded {img_path.name} - Mode: {img.mode}, Size: {img.size}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {str(e)}\")\n",
    "\n",
    "base_directory = Path('.')\n",
    "load_images_from_folders(base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6ccdd2c-530c-4648-9baf-d61d71259919",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train folder for renaming:\n",
      "\n",
      "Folder 1: Renaming 6 images\n",
      "Renamed f401_01_f12_i0_0.png to 1_1.png\n",
      "Renamed f401_01_p01_i0_0.png to 1_2.png\n",
      "Renamed f401_02_f12_i0_0.png to 1_3.png\n",
      "Renamed f401_02_p01_i0_0.png to 1_4.png\n",
      "Renamed f401_03_f12_i0_0.png to 1_5.png\n",
      "Renamed f401_03_p01_i0_0.png to 1_6.png\n",
      "\n",
      "Folder 2: Renaming 6 images\n",
      "Renamed f402_01_f12_i0_0.png to 2_1.png\n",
      "Renamed f402_01_p01_i0_0.png to 2_2.png\n",
      "Renamed f402_02_f12_i0_0.png to 2_3.png\n",
      "Renamed f402_02_p01_i0_0.png to 2_4.png\n",
      "Renamed f402_03_f12_i0_0.png to 2_5.png\n",
      "Renamed f402_03_p01_i0_0.png to 2_6.png\n",
      "\n",
      "Folder 3: Renaming 6 images\n",
      "Renamed f403_01_f12_i0_0.png to 3_1.png\n",
      "Renamed f403_01_p01_i0_0.png to 3_2.png\n",
      "Renamed f403_02_f12_i0_0.png to 3_3.png\n",
      "Renamed f403_02_p01_i0_0.png to 3_4.png\n",
      "Renamed f403_03_f12_i0_0.png to 3_5.png\n",
      "Renamed f403_03_p01_i0_0.png to 3_6.png\n",
      "Subfolder 4 not found\n",
      "Subfolder 5 not found\n",
      "Subfolder 6 not found\n",
      "Subfolder 7 not found\n",
      "Subfolder 8 not found\n",
      "Subfolder 9 not found\n",
      "Subfolder 10 not found\n",
      "Subfolder 11 not found\n",
      "Subfolder 12 not found\n",
      "Subfolder 13 not found\n",
      "Subfolder 14 not found\n",
      "Subfolder 15 not found\n",
      "Subfolder 16 not found\n",
      "Subfolder 17 not found\n",
      "Subfolder 18 not found\n",
      "Subfolder 19 not found\n",
      "Subfolder 20 not found\n",
      "Subfolder 21 not found\n",
      "Subfolder 22 not found\n",
      "Subfolder 23 not found\n",
      "Subfolder 24 not found\n",
      "Subfolder 25 not found\n",
      "Subfolder 26 not found\n",
      "Subfolder 27 not found\n",
      "Subfolder 28 not found\n",
      "Subfolder 29 not found\n",
      "Subfolder 30 not found\n",
      "Subfolder 31 not found\n"
     ]
    }
   ],
   "source": [
    "def rename_images_in_folders(base_path):\n",
    "    folder_path = base_path / 'train'\n",
    "    print(f\"Processing train folder for renaming:\")\n",
    "    \n",
    "    if not folder_path.exists():\n",
    "        print(\"Train folder not found!\")\n",
    "        return\n",
    "    \n",
    "    # Process folders 1-31\n",
    "    for folder_num in range(1, 32):\n",
    "        subfolder = folder_path / str(folder_num)\n",
    "        \n",
    "        if not subfolder.exists():\n",
    "            print(f\"Subfolder {folder_num} not found\")\n",
    "            continue\n",
    "            \n",
    "        image_files = sorted(subfolder.glob('*.png'))\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"No PNG images found in {subfolder}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nFolder {folder_num}: Renaming {len(image_files)} images\")\n",
    "        for i, img_path in enumerate(image_files, start=1):\n",
    "            try:\n",
    "                # Create new filename\n",
    "                new_name = f\"{folder_num}_{i}.png\"\n",
    "                new_path = subfolder / new_name\n",
    "                \n",
    "                # Rename the file\n",
    "                os.rename(img_path, new_path)\n",
    "                print(f\"Renamed {img_path.name} to {new_name}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error renaming {img_path}: {str(e)}\")\n",
    "\n",
    "base_directory = Path('.')\n",
    "rename_images_in_folders(base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24981cad-e3c6-47ad-a28c-f89fcc46095f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train folder:\n",
      "\n",
      "Folder 1: Loading 6 images\n",
      "Loaded f401_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f401_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f401_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f401_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f401_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f401_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 2: Loading 6 images\n",
      "Loaded f402_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f402_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f402_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f402_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f402_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f402_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "\n",
      "Folder 3: Loading 6 images\n",
      "Loaded f403_01_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f403_01_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f403_02_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f403_02_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f403_03_f12_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Loaded f403_03_p01_i0_0.png - Mode: RGB, Size: (80, 80)\n",
      "Subfolder 4 not found\n",
      "Subfolder 5 not found\n",
      "Subfolder 6 not found\n",
      "Subfolder 7 not found\n",
      "Subfolder 8 not found\n",
      "Subfolder 9 not found\n",
      "Subfolder 10 not found\n",
      "Subfolder 11 not found\n",
      "Subfolder 12 not found\n",
      "Subfolder 13 not found\n",
      "Subfolder 14 not found\n",
      "Subfolder 15 not found\n",
      "Subfolder 16 not found\n",
      "Subfolder 17 not found\n",
      "Subfolder 18 not found\n",
      "Subfolder 19 not found\n",
      "Subfolder 20 not found\n",
      "Subfolder 21 not found\n",
      "Subfolder 22 not found\n",
      "Subfolder 23 not found\n",
      "Subfolder 24 not found\n",
      "Subfolder 25 not found\n",
      "Subfolder 26 not found\n",
      "Subfolder 27 not found\n",
      "Subfolder 28 not found\n",
      "Subfolder 29 not found\n",
      "Subfolder 30 not found\n",
      "Subfolder 31 not found\n"
     ]
    }
   ],
   "source": [
    "def load_images_from_folders(base_path):\n",
    "    folder_path = base_path / 'train'\n",
    "    print(f\"Processing train folder:\")\n",
    "    \n",
    "    if not folder_path.exists():\n",
    "        print(\"Train folder not found!\")\n",
    "        return\n",
    "    \n",
    "    # Process folders 1-31\n",
    "    for folder_num in range(1, 32):\n",
    "        subfolder = folder_path / str(folder_num)\n",
    "        \n",
    "        if not subfolder.exists():\n",
    "            print(f\"Subfolder {folder_num} not found\")\n",
    "            continue\n",
    "            \n",
    "        # Get all PNG files\n",
    "        image_files = sorted(subfolder.glob('*.png'))\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"No PNG images found in {subfolder}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nFolder {folder_num}: Loading {len(image_files)} images\")\n",
    "        for img_path in image_files:\n",
    "            try:\n",
    "                # Load with PIL (automatically RGB)\n",
    "                img = Image.open(img_path)\n",
    "                print(f\"Loaded {img_path.name} - Mode: {img.mode}, Size: {img.size}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {str(e)}\")\n",
    "\n",
    "base_directory = Path('.')\n",
    "load_images_from_folders(base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e88a49f-66e1-4761-8f91-4686f4103acb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train folder to remove non-PNG files:\n",
      "No non-PNG files found in train\\1\n",
      "No non-PNG files found in train\\2\n",
      "No non-PNG files found in train\\3\n",
      "\n",
      "Folder 4: Found 6 non-PNG files\n",
      "Removed f404_01_f12_i0_0.wav\n",
      "Removed f404_01_p01_i0_0.wav\n",
      "Removed f404_02_f12_i0_0.wav\n",
      "Removed f404_02_p01_i0_0.wav\n",
      "Removed f404_03_f12_i0_0.wav\n",
      "Removed f404_03_p01_i0_0.wav\n",
      "\n",
      "Folder 5: Found 6 non-PNG files\n",
      "Removed f405_01_f12_i0_0.wav\n",
      "Removed f405_01_p01_i0_0.wav\n",
      "Removed f405_02_f12_i0_0.wav\n",
      "Removed f405_02_p01_i0_0.wav\n",
      "Removed f405_03_f12_i0_0.wav\n",
      "Removed f405_03_p01_i0_0.wav\n",
      "\n",
      "Folder 6: Found 6 non-PNG files\n",
      "Removed f406_01_f12_i0_0.wav\n",
      "Removed f406_01_p01_i0_0.wav\n",
      "Removed f406_02_f12_i0_0.wav\n",
      "Removed f406_02_p01_i0_0.wav\n",
      "Removed f406_03_p01_i0_0.wav\n",
      "Removed f406_03_r06_i0_0.wav\n",
      "\n",
      "Folder 7: Found 6 non-PNG files\n",
      "Removed f407_01_f12_i0_0.wav\n",
      "Removed f407_01_p01_i0_0.wav\n",
      "Removed f407_02_f12_i0_0.wav\n",
      "Removed f407_02_p01_i0_0.wav\n",
      "Removed f407_03_f12_i0_0.wav\n",
      "Removed f407_03_p01_i0_0.wav\n",
      "\n",
      "Folder 8: Found 6 non-PNG files\n",
      "Removed f408_01_f12_i0_0.wav\n",
      "Removed f408_01_p01_i0_0.wav\n",
      "Removed f408_02_f12_i0_0.wav\n",
      "Removed f408_02_p01_i0_0.wav\n",
      "Removed f408_03_f12_i0_0.wav\n",
      "Removed f408_03_p01_i0_0.wav\n",
      "\n",
      "Folder 9: Found 6 non-PNG files\n",
      "Removed f409_01_f12_i0_0.wav\n",
      "Removed f409_01_p01_i0_0.wav\n",
      "Removed f409_02_f12_i0_0.wav\n",
      "Removed f409_02_p01_i0_0.wav\n",
      "Removed f409_03_f12_i0_0.wav\n",
      "Removed f409_03_p01_i0_0.wav\n",
      "\n",
      "Folder 10: Found 6 non-PNG files\n",
      "Removed f410_01_f12_i0_0.wav\n",
      "Removed f410_01_p01_i0_0.wav\n",
      "Removed f410_02_f21_i0_0.wav\n",
      "Removed f410_02_p01_i0_0.wav\n",
      "Removed f410_03_f12_i0_0.wav\n",
      "Removed f410_03_p01_i0_0.wav\n",
      "\n",
      "Folder 11: Found 6 non-PNG files\n",
      "Removed f411_01_f12_i0_0.wav\n",
      "Removed f411_01_r06_i0_0.wav\n",
      "Removed f411_02_f12_i0_0.wav\n",
      "Removed f411_02_p01_i0_0.wav\n",
      "Removed f411_03_f12_i0_0.wav\n",
      "Removed f411_03_p01_i0_0.wav\n",
      "\n",
      "Folder 12: Found 6 non-PNG files\n",
      "Removed f412_01_f12_i0_0.wav\n",
      "Removed f412_01_p01_i0_0.wav\n",
      "Removed f412_02_f12_i0_0.wav\n",
      "Removed f412_02_p01_i0_0.wav\n",
      "Removed f412_03_f12_i0_0.wav\n",
      "Removed f412_03_p01_i0_0.wav\n",
      "\n",
      "Folder 13: Found 6 non-PNG files\n",
      "Removed f413_01_f12_i0_0.wav\n",
      "Removed f413_01_p01_i0_0.wav\n",
      "Removed f413_02_f12_i0_0.wav\n",
      "Removed f413_02_p01_i0_0.wav\n",
      "Removed f413_03_f12_i0_0.wav\n",
      "Removed f413_03_p01_i0_0.wav\n",
      "\n",
      "Folder 14: Found 6 non-PNG files\n",
      "Removed f415_01_f12_i0_0.wav\n",
      "Removed f415_01_p01_i0_0.wav\n",
      "Removed f415_02_f12_i0_0.wav\n",
      "Removed f415_02_p01_i0_0.wav\n",
      "Removed f415_03_f12_i0_0.wav\n",
      "Removed f415_03_p01_i0_0.wav\n",
      "\n",
      "Folder 15: Found 6 non-PNG files\n",
      "Removed f433_01_f12_i0_0.wav\n",
      "Removed f433_01_p01_i0_0.wav\n",
      "Removed f433_02_f12_i0_0.wav\n",
      "Removed f433_02_p01_i0_0.wav\n",
      "Removed f433_03_f12_i0_0.wav\n",
      "Removed f433_03_p01_i0_0.wav\n",
      "\n",
      "Folder 16: Found 6 non-PNG files\n",
      "Removed m414_01_f12_i0_0.wav\n",
      "Removed m414_01_p01_i0_0.wav\n",
      "Removed m414_02_f12_i0_0.wav\n",
      "Removed m414_02_p01_i0_0.wav\n",
      "Removed m414_03_f12_i0_0.wav\n",
      "Removed m414_03_p01_i0_0.wav\n",
      "\n",
      "Folder 17: Found 6 non-PNG files\n",
      "Removed m417_01_f12_i0_0.wav\n",
      "Removed m417_01_p01_i0_0.wav\n",
      "Removed m417_02_f12_i0_0.wav\n",
      "Removed m417_02_p01_i0_0.wav\n",
      "Removed m417_03_f12_i0_0.wav\n",
      "Removed m417_03_p01_i0_0.wav\n",
      "\n",
      "Folder 18: Found 6 non-PNG files\n",
      "Removed m419_01_f12_i0_0.wav\n",
      "Removed m419_01_p01_i0_0.wav\n",
      "Removed m419_02_f12_i0_0.wav\n",
      "Removed m419_02_p01_i0_0.wav\n",
      "Removed m419_03_f12_i0_0.wav\n",
      "Removed m419_03_p01_i0_0.wav\n",
      "\n",
      "Folder 19: Found 6 non-PNG files\n",
      "Removed m420_01_f12_i0_0.wav\n",
      "Removed m420_01_p01_i0_0.wav\n",
      "Removed m420_02_f12_i0_0.wav\n",
      "Removed m420_02_p01_i0_0.wav\n",
      "Removed m420_03_f12_i0_0.wav\n",
      "Removed m420_03_p01_i0_0.wav\n",
      "\n",
      "Folder 20: Found 6 non-PNG files\n",
      "Removed m421_01_f12_i0_0.wav\n",
      "Removed m421_01_p01_i0_0.wav\n",
      "Removed m421_02_f12_i0_0.wav\n",
      "Removed m421_02_p01_i0_0.wav\n",
      "Removed m421_03_f12_i0_0.wav\n",
      "Removed m421_03_p01_i0_0.wav\n",
      "\n",
      "Folder 21: Found 6 non-PNG files\n",
      "Removed m422_01_f12_i0_0.wav\n",
      "Removed m422_01_p01_i0_0.wav\n",
      "Removed m422_02_f12_i0_0.wav\n",
      "Removed m422_02_p01_i0_0.wav\n",
      "Removed m422_03_f12_i0_0.wav\n",
      "Removed m422_03_p01_i0_0.wav\n",
      "\n",
      "Folder 22: Found 6 non-PNG files\n",
      "Removed m423_01_f12_i0_0.wav\n",
      "Removed m423_01_p01_i0_0.wav\n",
      "Removed m423_02_f12_i0_0.wav\n",
      "Removed m423_02_p01_i0_0.wav\n",
      "Removed m423_03_f12_i0_0.wav\n",
      "Removed m423_03_p01_i0_0.wav\n",
      "\n",
      "Folder 23: Found 6 non-PNG files\n",
      "Removed m424_01_f12_i0_0.wav\n",
      "Removed m424_01_p01_i0_0.wav\n",
      "Removed m424_02_f12_i0_0.wav\n",
      "Removed m424_02_p01_i0_0.wav\n",
      "Removed m424_03_f12_i0_0.wav\n",
      "Removed m424_03_p01_i0_0.wav\n",
      "\n",
      "Folder 24: Found 6 non-PNG files\n",
      "Removed m425_01_f12_i0_0.wav\n",
      "Removed m425_01_p01_i0_0.wav\n",
      "Removed m425_02_f12_i0_0.wav\n",
      "Removed m425_02_p01_i0_0.wav\n",
      "Removed m425_03_f12_i0_0.wav\n",
      "Removed m425_03_p01_i0_0.wav\n",
      "\n",
      "Folder 25: Found 6 non-PNG files\n",
      "Removed m426_01_f12_i0_0.wav\n",
      "Removed m426_01_p01_i0_0.wav\n",
      "Removed m426_02_f12_i0_0.wav\n",
      "Removed m426_02_p01_i0_0.wav\n",
      "Removed m426_03_f12_i0_0.wav\n",
      "Removed m426_03_p01_i0_0.wav\n",
      "\n",
      "Folder 26: Found 6 non-PNG files\n",
      "Removed m427_01_f12_i0_0.wav\n",
      "Removed m427_01_p01_i0_0.wav\n",
      "Removed m427_02_f12_i0_0.wav\n",
      "Removed m427_02_p01_i0_0.wav\n",
      "Removed m427_03_f12_i0_0.wav\n",
      "Removed m427_03_p01_i0_0.wav\n",
      "\n",
      "Folder 27: Found 6 non-PNG files\n",
      "Removed m428_01_f12_i0_0.wav\n",
      "Removed m428_01_p01_i0_0.wav\n",
      "Removed m428_02_f12_i0_0.wav\n",
      "Removed m428_02_p01_i0_0.wav\n",
      "Removed m428_03_f12_i0_0.wav\n",
      "Removed m428_03_p01_i0_0.wav\n",
      "\n",
      "Folder 28: Found 6 non-PNG files\n",
      "Removed m429_01_f12_i0_0.wav\n",
      "Removed m429_01_p01_i0_0.wav\n",
      "Removed m429_02_f12_i0_0.wav\n",
      "Removed m429_02_p01_i0_0.wav\n",
      "Removed m429_03_f12_i0_0.wav\n",
      "Removed m429_03_p01_i0_0.wav\n",
      "\n",
      "Folder 29: Found 6 non-PNG files\n",
      "Removed m430_01_f12_i0_0.wav\n",
      "Removed m430_01_p01_i0_0.wav\n",
      "Removed m430_02_f12_i0_0.wav\n",
      "Removed m430_02_p01_i0_0.wav\n",
      "Removed m430_03_f12_i0_0.wav\n",
      "Removed m430_03_p01_i0_0.wav\n",
      "\n",
      "Folder 30: Found 6 non-PNG files\n",
      "Removed m431_01_f12_i0_0.wav\n",
      "Removed m431_01_p01_i0_0.wav\n",
      "Removed m431_02_f12_i0_0.wav\n",
      "Removed m431_02_p01_i0_0.wav\n",
      "Removed m431_03_f12_i0_0.wav\n",
      "Removed m431_03_p01_i0_0.wav\n",
      "\n",
      "Folder 31: Found 6 non-PNG files\n",
      "Removed m432_01_f12_i0_0.wav\n",
      "Removed m432_01_p01_i0_0.wav\n",
      "Removed m432_02_f12_i0_0.wav\n",
      "Removed m432_02_p01_i0_0.wav\n",
      "Removed m432_03_f12_i0_0.wav\n",
      "Removed m432_03_p01_i0_0.wav\n"
     ]
    }
   ],
   "source": [
    "# For other cells needs to remove wav files!\n",
    "def remove_non_png_files(base_path):\n",
    "    folder_path = base_path / 'train'\n",
    "    #folder_path = base_path / 'dev'\n",
    "    print(f\"Processing train folder to remove non-PNG files:\")\n",
    "    \n",
    "    if not folder_path.exists():\n",
    "        print(\"Train folder not found!\")\n",
    "        return\n",
    "    \n",
    "    # Process folders 1-31\n",
    "    for folder_num in range(1, 32):\n",
    "        subfolder = folder_path / str(folder_num)\n",
    "        \n",
    "        if not subfolder.exists():\n",
    "            print(f\"Subfolder {folder_num} not found\")\n",
    "            continue\n",
    "            \n",
    "        # Get all files (not just PNGs)\n",
    "        all_files = list(subfolder.glob('*'))\n",
    "        png_files = list(subfolder.glob('*.png'))\n",
    "        non_png_files = [f for f in all_files if f not in png_files]\n",
    "        \n",
    "        if not non_png_files:\n",
    "            print(f\"No non-PNG files found in {subfolder}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nFolder {folder_num}: Found {len(non_png_files)} non-PNG files\")\n",
    "        for file_path in non_png_files:\n",
    "            try:\n",
    "                # Delete the file\n",
    "                os.remove(file_path)\n",
    "                print(f\"Removed {file_path.name}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error removing {file_path}: {str(e)}\")\n",
    "\n",
    "# Usage\n",
    "base_directory = Path('.')  # Current directory or specify your path\n",
    "remove_non_png_files(base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146eb99f-8063-48d3-962f-86f462e60cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Nejako to prerozdelit do slovnika alebo pola uvidis\n",
    "# TODO: Mozno premenovat tie subory, aby sa s nimi lepsie pracovalo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44f0277b-9834-49de-94a1-a3ca0309673d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from albumentations import Compose, HorizontalFlip, ShiftScaleRotate, RandomBrightnessContrast\n",
    "\n",
    "# Setup paths\n",
    "folder_path = './train'\n",
    "input_dir = folder_path\n",
    "output_dir = folder_path \n",
    "\n",
    "# Create 3 augmented versions per image\n",
    "n_augments = 3  \n",
    "\n",
    "def add_gaussian_noise(image, mean=0, std_range=(5, 15)):\n",
    "    \"\"\"Add gentle Gaussian noise to an image\"\"\"\n",
    "    std = np.random.uniform(*std_range)\n",
    "    img_array = np.array(image).astype(np.float32)\n",
    "    noise = np.random.normal(mean, std, img_array.shape)\n",
    "    noisy_array = np.clip(img_array + noise, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(noisy_array)\n",
    "\n",
    "def darken_and_flip_horizontal(image, darken_factor=0.8):\n",
    "    \"\"\"More subtle darkening with optional flip\"\"\"\n",
    "    img_array = np.array(image)\n",
    "    img_array = np.clip(img_array * darken_factor, 0, 255).astype(np.uint8)\n",
    "    if np.random.rand() > 0.5:  # 50% chance to flip\n",
    "        img_array = np.fliplr(img_array)\n",
    "    return Image.fromarray(img_array)\n",
    "\n",
    "transform = Compose([\n",
    "    HorizontalFlip(p=0.3),\n",
    "    ShiftScaleRotate(shift_limit=0.02, rotate_limit=5),\n",
    "    RandomBrightnessContrast(p=0.5),\n",
    "    RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n",
    "    GaussianBlur(blur_limit=(1, 3), p=0.2),\n",
    "])\n",
    "\n",
    "for class_dir in os.listdir(input_dir):\n",
    "    class_path = os.path.join(input_dir, class_dir)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "        \n",
    "    os.makedirs(f\"{output_dir}/{class_dir}\", exist_ok=True)\n",
    "    \n",
    "    for img_file in os.listdir(class_path):\n",
    "        file_path = os.path.join(class_path, img_file)\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(file_path).convert('RGB')\n",
    "            \n",
    "            for i in range(1, n_augments + 1):\n",
    "                augmented = transform(image=np.array(img))['image']\n",
    "                pil_img = Image.fromarray(augmented)\n",
    "                \n",
    "                if i == 1:\n",
    "                    pil_img = add_gaussian_noise(pil_img)\n",
    "                elif i == 2:\n",
    "                    pil_img = darken_and_flip_horizontal(pil_img)\n",
    "                elif i == 3:\n",
    "                    pil_img = darken_and_flip_horizontal(pil_img)\n",
    "                    pil_img = add_gaussian_noise(pil_img)\n",
    "                \n",
    "                pil_img.save(f\"{output_dir}/{class_dir}/{Path(img_file).stem}_{i}.jpg\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "print(\"Augmentation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9a89523e-0c09-4fe3-9c67-c6f1316ccef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1/5 ===\n",
      "Epoch 1/40 | Loss: 4.7500 | Val Acc: 2.63%\n",
      "Epoch 2/40 | Loss: 3.1388 | Val Acc: 18.42%\n",
      "Epoch 3/40 | Loss: 1.8618 | Val Acc: 0.00%\n",
      "Epoch 4/40 | Loss: 1.2222 | Val Acc: 13.16%\n",
      "Epoch 5/40 | Loss: 0.7280 | Val Acc: 10.53%\n",
      "Epoch 6/40 | Loss: 0.3751 | Val Acc: 21.05%\n",
      "Epoch 7/40 | Loss: 0.2357 | Val Acc: 26.32%\n",
      "Epoch 8/40 | Loss: 0.1594 | Val Acc: 39.47%\n",
      "Epoch 9/40 | Loss: 0.1089 | Val Acc: 52.63%\n",
      "Epoch 10/40 | Loss: 0.1171 | Val Acc: 68.42%\n",
      "Epoch 11/40 | Loss: 0.0549 | Val Acc: 71.05%\n",
      "Epoch 12/40 | Loss: 0.0342 | Val Acc: 65.79%\n",
      "Epoch 13/40 | Loss: 0.0369 | Val Acc: 63.16%\n",
      "Epoch 14/40 | Loss: 0.0338 | Val Acc: 78.95%\n",
      "Epoch 15/40 | Loss: 0.0195 | Val Acc: 78.95%\n",
      "Epoch 16/40 | Loss: 0.0205 | Val Acc: 78.95%\n",
      "Epoch 17/40 | Loss: 0.0143 | Val Acc: 73.68%\n",
      "Epoch 18/40 | Loss: 0.0112 | Val Acc: 73.68%\n",
      "Epoch 19/40 | Loss: 0.0159 | Val Acc: 73.68%\n",
      "Epoch 20/40 | Loss: 0.0100 | Val Acc: 73.68%\n",
      "Epoch 21/40 | Loss: 0.0106 | Val Acc: 73.68%\n",
      "Epoch 22/40 | Loss: 0.0096 | Val Acc: 73.68%\n",
      "Epoch 23/40 | Loss: 0.0078 | Val Acc: 71.05%\n",
      "Epoch 24/40 | Loss: 0.0081 | Val Acc: 76.32%\n",
      "Epoch 25/40 | Loss: 0.0054 | Val Acc: 76.32%\n",
      "Epoch 26/40 | Loss: 0.0055 | Val Acc: 76.32%\n",
      "Epoch 27/40 | Loss: 0.0036 | Val Acc: 76.32%\n",
      "Epoch 28/40 | Loss: 0.0047 | Val Acc: 76.32%\n",
      "Epoch 29/40 | Loss: 0.0044 | Val Acc: 73.68%\n",
      "Epoch 30/40 | Loss: 0.0041 | Val Acc: 73.68%\n",
      "Epoch 31/40 | Loss: 0.0037 | Val Acc: 73.68%\n",
      "Epoch 32/40 | Loss: 0.0024 | Val Acc: 73.68%\n",
      "Epoch 33/40 | Loss: 0.0033 | Val Acc: 73.68%\n",
      "Epoch 34/40 | Loss: 0.0028 | Val Acc: 76.32%\n",
      "Epoch 35/40 | Loss: 0.0038 | Val Acc: 76.32%\n",
      "Epoch 36/40 | Loss: 0.0019 | Val Acc: 76.32%\n",
      "Epoch 37/40 | Loss: 0.0021 | Val Acc: 76.32%\n",
      "Epoch 38/40 | Loss: 0.0024 | Val Acc: 76.32%\n",
      "Epoch 39/40 | Loss: 0.0021 | Val Acc: 73.68%\n",
      "Epoch 40/40 | Loss: 0.0040 | Val Acc: 76.32%\n",
      "Fold 1 Best Val Acc: 78.95%\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "Epoch 1/40 | Loss: 5.2554 | Val Acc: 8.11%\n",
      "Epoch 2/40 | Loss: 3.9313 | Val Acc: 8.11%\n",
      "Epoch 3/40 | Loss: 2.9204 | Val Acc: 21.62%\n",
      "Epoch 4/40 | Loss: 2.2061 | Val Acc: 8.11%\n",
      "Epoch 5/40 | Loss: 1.5495 | Val Acc: 37.84%\n",
      "Epoch 6/40 | Loss: 1.1536 | Val Acc: 40.54%\n",
      "Epoch 7/40 | Loss: 0.9213 | Val Acc: 35.14%\n",
      "Epoch 8/40 | Loss: 0.5315 | Val Acc: 70.27%\n",
      "Epoch 9/40 | Loss: 0.3448 | Val Acc: 70.27%\n",
      "Epoch 10/40 | Loss: 0.2675 | Val Acc: 70.27%\n",
      "Epoch 11/40 | Loss: 0.1478 | Val Acc: 72.97%\n",
      "Epoch 12/40 | Loss: 0.1242 | Val Acc: 78.38%\n",
      "Epoch 13/40 | Loss: 0.0936 | Val Acc: 83.78%\n",
      "Epoch 14/40 | Loss: 0.0898 | Val Acc: 83.78%\n",
      "Epoch 15/40 | Loss: 0.0690 | Val Acc: 86.49%\n",
      "Epoch 16/40 | Loss: 0.0522 | Val Acc: 83.78%\n",
      "Epoch 17/40 | Loss: 0.0458 | Val Acc: 81.08%\n",
      "Epoch 18/40 | Loss: 0.0318 | Val Acc: 83.78%\n",
      "Epoch 19/40 | Loss: 0.0241 | Val Acc: 91.89%\n",
      "Epoch 20/40 | Loss: 0.0236 | Val Acc: 89.19%\n",
      "Epoch 21/40 | Loss: 0.0264 | Val Acc: 89.19%\n",
      "Epoch 22/40 | Loss: 0.0174 | Val Acc: 86.49%\n",
      "Epoch 23/40 | Loss: 0.0178 | Val Acc: 89.19%\n",
      "Epoch 24/40 | Loss: 0.0120 | Val Acc: 89.19%\n",
      "Epoch 25/40 | Loss: 0.0210 | Val Acc: 86.49%\n",
      "Epoch 26/40 | Loss: 0.0160 | Val Acc: 83.78%\n",
      "Epoch 27/40 | Loss: 0.0114 | Val Acc: 83.78%\n",
      "Epoch 28/40 | Loss: 0.0084 | Val Acc: 89.19%\n",
      "Epoch 29/40 | Loss: 0.0168 | Val Acc: 89.19%\n",
      "Epoch 30/40 | Loss: 0.0145 | Val Acc: 89.19%\n",
      "Epoch 31/40 | Loss: 0.0117 | Val Acc: 89.19%\n",
      "Epoch 32/40 | Loss: 0.0071 | Val Acc: 89.19%\n",
      "Epoch 33/40 | Loss: 0.0111 | Val Acc: 89.19%\n",
      "Epoch 34/40 | Loss: 0.0071 | Val Acc: 89.19%\n",
      "Epoch 35/40 | Loss: 0.0075 | Val Acc: 89.19%\n",
      "Epoch 36/40 | Loss: 0.0082 | Val Acc: 89.19%\n",
      "Epoch 37/40 | Loss: 0.0061 | Val Acc: 86.49%\n",
      "Epoch 38/40 | Loss: 0.0056 | Val Acc: 86.49%\n",
      "Epoch 39/40 | Loss: 0.0081 | Val Acc: 86.49%\n",
      "Epoch 40/40 | Loss: 0.0054 | Val Acc: 86.49%\n",
      "Fold 2 Best Val Acc: 91.89%\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "Epoch 1/40 | Loss: 4.8082 | Val Acc: 8.11%\n",
      "Epoch 2/40 | Loss: 3.6037 | Val Acc: 2.70%\n",
      "Epoch 3/40 | Loss: 2.1877 | Val Acc: 10.81%\n",
      "Epoch 4/40 | Loss: 1.2947 | Val Acc: 13.51%\n",
      "Epoch 5/40 | Loss: 0.8746 | Val Acc: 16.22%\n",
      "Epoch 6/40 | Loss: 0.5643 | Val Acc: 24.32%\n",
      "Epoch 7/40 | Loss: 0.3802 | Val Acc: 27.03%\n",
      "Epoch 8/40 | Loss: 0.1858 | Val Acc: 32.43%\n",
      "Epoch 9/40 | Loss: 0.1319 | Val Acc: 48.65%\n",
      "Epoch 10/40 | Loss: 0.0881 | Val Acc: 48.65%\n",
      "Epoch 11/40 | Loss: 0.0596 | Val Acc: 48.65%\n",
      "Epoch 12/40 | Loss: 0.0425 | Val Acc: 56.76%\n",
      "Epoch 13/40 | Loss: 0.0400 | Val Acc: 56.76%\n",
      "Epoch 14/40 | Loss: 0.0274 | Val Acc: 54.05%\n",
      "Epoch 15/40 | Loss: 0.0212 | Val Acc: 62.16%\n",
      "Epoch 16/40 | Loss: 0.0166 | Val Acc: 64.86%\n",
      "Epoch 17/40 | Loss: 0.0114 | Val Acc: 67.57%\n",
      "Epoch 18/40 | Loss: 0.0110 | Val Acc: 64.86%\n",
      "Epoch 19/40 | Loss: 0.0104 | Val Acc: 64.86%\n",
      "Epoch 20/40 | Loss: 0.0112 | Val Acc: 64.86%\n",
      "Epoch 21/40 | Loss: 0.0122 | Val Acc: 64.86%\n",
      "Epoch 22/40 | Loss: 0.0094 | Val Acc: 64.86%\n",
      "Epoch 23/40 | Loss: 0.0057 | Val Acc: 64.86%\n",
      "Epoch 24/40 | Loss: 0.0055 | Val Acc: 64.86%\n",
      "Epoch 25/40 | Loss: 0.0068 | Val Acc: 64.86%\n",
      "Epoch 26/40 | Loss: 0.0061 | Val Acc: 62.16%\n",
      "Epoch 27/40 | Loss: 0.0074 | Val Acc: 62.16%\n",
      "Epoch 28/40 | Loss: 0.0051 | Val Acc: 59.46%\n",
      "Epoch 29/40 | Loss: 0.0038 | Val Acc: 59.46%\n",
      "Epoch 30/40 | Loss: 0.0093 | Val Acc: 62.16%\n",
      "Epoch 31/40 | Loss: 0.0033 | Val Acc: 64.86%\n",
      "Epoch 32/40 | Loss: 0.0043 | Val Acc: 67.57%\n",
      "Epoch 33/40 | Loss: 0.0041 | Val Acc: 70.27%\n",
      "Epoch 34/40 | Loss: 0.0041 | Val Acc: 78.38%\n",
      "Epoch 35/40 | Loss: 0.0026 | Val Acc: 75.68%\n",
      "Epoch 36/40 | Loss: 0.0051 | Val Acc: 72.97%\n",
      "Epoch 37/40 | Loss: 0.0035 | Val Acc: 72.97%\n",
      "Epoch 38/40 | Loss: 0.0027 | Val Acc: 72.97%\n",
      "Epoch 39/40 | Loss: 0.0037 | Val Acc: 70.27%\n",
      "Epoch 40/40 | Loss: 0.0030 | Val Acc: 70.27%\n",
      "Fold 3 Best Val Acc: 78.38%\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "Epoch 1/40 | Loss: 5.6294 | Val Acc: 5.41%\n",
      "Epoch 2/40 | Loss: 3.9038 | Val Acc: 8.11%\n",
      "Epoch 3/40 | Loss: 2.9546 | Val Acc: 18.92%\n",
      "Epoch 4/40 | Loss: 1.9006 | Val Acc: 21.62%\n",
      "Epoch 5/40 | Loss: 1.3630 | Val Acc: 29.73%\n",
      "Epoch 6/40 | Loss: 0.9799 | Val Acc: 27.03%\n",
      "Epoch 7/40 | Loss: 0.6818 | Val Acc: 35.14%\n",
      "Epoch 8/40 | Loss: 0.4649 | Val Acc: 45.95%\n",
      "Epoch 9/40 | Loss: 0.3945 | Val Acc: 56.76%\n",
      "Epoch 10/40 | Loss: 0.2293 | Val Acc: 64.86%\n",
      "Epoch 11/40 | Loss: 0.2289 | Val Acc: 62.16%\n",
      "Epoch 12/40 | Loss: 0.1117 | Val Acc: 72.97%\n",
      "Epoch 13/40 | Loss: 0.1178 | Val Acc: 75.68%\n",
      "Epoch 14/40 | Loss: 0.0715 | Val Acc: 78.38%\n",
      "Epoch 15/40 | Loss: 0.1051 | Val Acc: 75.68%\n",
      "Epoch 16/40 | Loss: 0.0439 | Val Acc: 81.08%\n",
      "Epoch 17/40 | Loss: 0.0359 | Val Acc: 81.08%\n",
      "Epoch 18/40 | Loss: 0.0324 | Val Acc: 75.68%\n",
      "Epoch 19/40 | Loss: 0.0359 | Val Acc: 72.97%\n",
      "Epoch 20/40 | Loss: 0.0450 | Val Acc: 72.97%\n",
      "Epoch 21/40 | Loss: 0.0193 | Val Acc: 72.97%\n",
      "Epoch 22/40 | Loss: 0.0177 | Val Acc: 72.97%\n",
      "Epoch 23/40 | Loss: 0.0163 | Val Acc: 78.38%\n",
      "Epoch 24/40 | Loss: 0.0117 | Val Acc: 78.38%\n",
      "Epoch 25/40 | Loss: 0.0109 | Val Acc: 81.08%\n",
      "Epoch 26/40 | Loss: 0.0128 | Val Acc: 81.08%\n",
      "Epoch 27/40 | Loss: 0.0123 | Val Acc: 83.78%\n",
      "Epoch 28/40 | Loss: 0.0085 | Val Acc: 81.08%\n",
      "Epoch 29/40 | Loss: 0.0164 | Val Acc: 78.38%\n",
      "Epoch 30/40 | Loss: 0.0092 | Val Acc: 75.68%\n",
      "Epoch 31/40 | Loss: 0.0092 | Val Acc: 72.97%\n",
      "Epoch 32/40 | Loss: 0.0084 | Val Acc: 72.97%\n",
      "Epoch 33/40 | Loss: 0.0106 | Val Acc: 75.68%\n",
      "Epoch 34/40 | Loss: 0.0088 | Val Acc: 83.78%\n",
      "Epoch 35/40 | Loss: 0.0074 | Val Acc: 81.08%\n",
      "Epoch 36/40 | Loss: 0.0075 | Val Acc: 78.38%\n",
      "Epoch 37/40 | Loss: 0.0070 | Val Acc: 78.38%\n",
      "Epoch 38/40 | Loss: 0.0068 | Val Acc: 78.38%\n",
      "Epoch 39/40 | Loss: 0.0080 | Val Acc: 78.38%\n",
      "Epoch 40/40 | Loss: 0.0076 | Val Acc: 81.08%\n",
      "Fold 4 Best Val Acc: 83.78%\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "Epoch 1/40 | Loss: 4.6804 | Val Acc: 5.41%\n",
      "Epoch 2/40 | Loss: 3.3548 | Val Acc: 2.70%\n",
      "Epoch 3/40 | Loss: 2.0580 | Val Acc: 8.11%\n",
      "Epoch 4/40 | Loss: 1.1762 | Val Acc: 5.41%\n",
      "Epoch 5/40 | Loss: 0.8222 | Val Acc: 8.11%\n",
      "Epoch 6/40 | Loss: 0.4709 | Val Acc: 8.11%\n",
      "Epoch 7/40 | Loss: 0.2597 | Val Acc: 13.51%\n",
      "Epoch 8/40 | Loss: 0.2014 | Val Acc: 37.84%\n",
      "Epoch 9/40 | Loss: 0.1090 | Val Acc: 56.76%\n",
      "Epoch 10/40 | Loss: 0.0930 | Val Acc: 62.16%\n",
      "Epoch 11/40 | Loss: 0.0451 | Val Acc: 64.86%\n",
      "Epoch 12/40 | Loss: 0.0461 | Val Acc: 70.27%\n",
      "Epoch 13/40 | Loss: 0.0310 | Val Acc: 67.57%\n",
      "Epoch 14/40 | Loss: 0.0217 | Val Acc: 75.68%\n",
      "Epoch 15/40 | Loss: 0.0365 | Val Acc: 78.38%\n",
      "Epoch 16/40 | Loss: 0.0294 | Val Acc: 78.38%\n",
      "Epoch 17/40 | Loss: 0.0105 | Val Acc: 64.86%\n",
      "Epoch 18/40 | Loss: 0.0214 | Val Acc: 64.86%\n",
      "Epoch 19/40 | Loss: 0.0198 | Val Acc: 70.27%\n",
      "Epoch 20/40 | Loss: 0.0098 | Val Acc: 70.27%\n",
      "Epoch 21/40 | Loss: 0.0114 | Val Acc: 70.27%\n",
      "Epoch 22/40 | Loss: 0.0185 | Val Acc: 70.27%\n",
      "Epoch 23/40 | Loss: 0.0088 | Val Acc: 72.97%\n",
      "Epoch 24/40 | Loss: 0.0088 | Val Acc: 75.68%\n",
      "Epoch 25/40 | Loss: 0.0167 | Val Acc: 75.68%\n",
      "Epoch 26/40 | Loss: 0.0061 | Val Acc: 75.68%\n",
      "Epoch 27/40 | Loss: 0.0092 | Val Acc: 75.68%\n",
      "Epoch 28/40 | Loss: 0.0077 | Val Acc: 72.97%\n",
      "Epoch 29/40 | Loss: 0.0047 | Val Acc: 70.27%\n",
      "Epoch 30/40 | Loss: 0.0068 | Val Acc: 70.27%\n",
      "Epoch 31/40 | Loss: 0.0032 | Val Acc: 70.27%\n",
      "Epoch 32/40 | Loss: 0.0042 | Val Acc: 72.97%\n",
      "Epoch 33/40 | Loss: 0.0030 | Val Acc: 75.68%\n",
      "Epoch 34/40 | Loss: 0.0045 | Val Acc: 75.68%\n",
      "Epoch 35/40 | Loss: 0.0048 | Val Acc: 75.68%\n",
      "Epoch 36/40 | Loss: 0.0021 | Val Acc: 75.68%\n",
      "Epoch 37/40 | Loss: 0.0020 | Val Acc: 78.38%\n",
      "Epoch 38/40 | Loss: 0.0022 | Val Acc: 75.68%\n",
      "Epoch 39/40 | Loss: 0.0032 | Val Acc: 75.68%\n",
      "Epoch 40/40 | Loss: 0.0048 | Val Acc: 75.68%\n",
      "Fold 5 Best Val Acc: 78.38%\n",
      "\n",
      "=== Cross-Validation Results ===\n",
      "Individual fold accuracies: [78.94736842105263, 91.89189189189189, 78.37837837837837, 83.78378378378379, 78.37837837837837]\n",
      "Mean validation accuracy: 82.28% (±5.22)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "torch.backends.openmp.enabled = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model definition (keep your existing FaceCNN class)\n",
    "class FaceCNN(nn.Module):\n",
    "    def __init__(self, num_classes=31):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*10*10, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Transforms (keep your improved transforms)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load full dataset\n",
    "full_dataset = datasets.ImageFolder('./train', transform=train_transform)\n",
    "\n",
    "# K-Fold setup\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(full_dataset)):\n",
    "    print(f\"\\n=== Fold {fold + 1}/{n_splits} ===\")\n",
    "    \n",
    "    # Create subsets\n",
    "    train_subset = Subset(full_dataset, train_idx)\n",
    "    val_subset = Subset(full_dataset, val_idx)\n",
    "    \n",
    "    # Apply val transform to validation\n",
    "    val_subset.dataset.transform = val_transform\n",
    "    \n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=32)\n",
    "    \n",
    "    # Model, optimizer, criterion\n",
    "    model = FaceCNN(num_classes=31).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4) \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(40):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_acc = 100 * correct / total\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), f'best_model_fold_{fold}.pth')\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/40 | Loss: {running_loss/len(train_loader):.4f} | '\n",
    "              f'Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    results.append(best_val_acc)\n",
    "    print(f'Fold {fold + 1} Best Val Acc: {best_val_acc:.2f}%')\n",
    "\n",
    "# Final results\n",
    "print(\"\\n=== Cross-Validation Results ===\")\n",
    "print(f\"Individual fold accuracies: {results}\")\n",
    "print(f\"Mean validation accuracy: {np.mean(results):.2f}% (±{np.std(results):.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "23e3f12f-6b6e-46e1-83ad-5e920f710052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamk\\AppData\\Local\\Temp\\ipykernel_10716\\1696123466.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'best_model_fold_{fold}.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Accuracy (Ensemble): 33.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamk\\AppData\\Local\\Temp\\ipykernel_10716\\1696123466.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(f'best_model_fold_{best_fold}.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (Single Best Model - Fold 2): 20.97%\n"
     ]
    }
   ],
   "source": [
    "# Prepare test data\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "test_data = datasets.ImageFolder('./dev', transform=test_transform)\n",
    "test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "# Ensemble evaluation (using all fold models)\n",
    "def evaluate_ensemble(test_loader, n_splits=5):\n",
    "    models = []\n",
    "    for fold in range(n_splits):\n",
    "        model = FaceCNN(num_classes=31).to(device)\n",
    "        model.load_state_dict(torch.load(f'best_model_fold_{fold}.pth'))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    \n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Get predictions from all models\n",
    "            outputs = torch.zeros((images.shape[0], 31)).to(device)\n",
    "            for model in models:\n",
    "                outputs += model(images)\n",
    "            \n",
    "            # Ensemble prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return 100 * correct / total\n",
    "\n",
    "# Evaluate\n",
    "test_acc = evaluate_ensemble(test_loader)\n",
    "print(f\"\\nFinal Test Accuracy (Ensemble): {test_acc:.2f}%\")\n",
    "\n",
    "# Optionally evaluate single best model\n",
    "best_fold = np.argmax(results)\n",
    "best_model = FaceCNN(num_classes=31).to(device)\n",
    "best_model.load_state_dict(torch.load(f'best_model_fold_{best_fold}.pth'))\n",
    "best_model.eval()\n",
    "\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy (Single Best Model - Fold {best_fold+1}): {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b88cf249-65a5-420c-ba86-7d4544594300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.set_num_threads(8)  # Match CPU core count\n",
    "torch.backends.openmp.enabled = True  # Enable OpenMP\n",
    "\n",
    "class FaceCNN(nn.Module):\n",
    "    def __init__(self, num_classes=31):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # 3x80x80 (RGB)\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # 32x80x80\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 32x40x40\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # 64x40x40\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 64x20x20\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),  # 128x20x20\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 128x10x10\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*10*10, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.7),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bba95e74-1e8f-47b2-a476-cd70af6ec18a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# class FaceCNN(nn.Module):\n",
    "#     def __init__(self, num_classes: int = 31, numChannels: int = 3):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.conv1 = nn.Conv2d(in_channels=numChannels, out_channels=16,\n",
    "#                                kernel_size=(5, 5))\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "#         self.conv2 = nn.Conv2d(in_channels=16, out_channels=32,\n",
    "#                                kernel_size=(5, 5), stride=1)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "#         self.norm4 = nn.InstanceNorm2d(32)\n",
    "\n",
    "#         self.fc1 = nn.Linear(in_features=9248, out_features=500)\n",
    "#         self.relu3 = nn.LeakyReLU()\n",
    "#         self.fc3 = nn.Linear(in_features=500, out_features=num_classes)\n",
    "#         self.Softmax = nn.Softmax(dim=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         \"\"\"Forward function for our neural network model\n",
    "\n",
    "#         Args:\n",
    "#             x: Input tensor\n",
    "\n",
    "#         Returns:\n",
    "#             torch.Tensor: Returns probabilities for each class created by soft max function.\n",
    "#         \"\"\"\n",
    "#         batch_size = x.shape[0]\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.relu1(x)\n",
    "#         x = self.maxpool1(x)\n",
    "#         # pass the input through the second set of CONV => RELU => POOL layers\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.relu2(x)\n",
    "#         x = self.maxpool2(x)\n",
    "#         x = self.norm4(x)\n",
    "#         x = x.permute(0, 3, 2, 1)\n",
    "#         x = x.reshape(batch_size, 9248)\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.relu3(x)\n",
    "#         x = self.fc3(x)\n",
    "#         x = self.Softmax(x)\n",
    "#         x = x.view(batch_size, 31)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fedbdc22-dcbf-44c7-a310-7870564cca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transformations\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.Resize((80, 80)),\n",
    "#     #transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # RGB\n",
    "# ])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.3),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.5, 0.5, 0.5],  # For all 3 channels\n",
    "#                         std=[0.5, 0.5, 0.5])\n",
    "# ])\n",
    "\n",
    "# val_transform = transforms.Compose([\n",
    "#     transforms.Resize((80, 80)),\n",
    "#     transforms.ToTensor(),\n",
    "#     # Ta normalizacia je z ImageNetu !!! Mozno prec!!\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],  # For all 3 channels\n",
    "                        std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_data = datasets.ImageFolder('./train', transform=train_transform)\n",
    "val_data = datasets.ImageFolder('./dev', transform=val_transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e63a2c0-426d-486d-b296-97ed41759032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch using: 16 CPU threads\n",
      "Optimization backend: x86\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch using: {torch.get_num_threads()} CPU threads\")\n",
    "print(f\"Optimization backend: {torch.backends.quantized.engine}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "63c18741-95f4-4910-baea-6f48bdf0a694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80 | Loss: 5.4205 | Val Acc: 0.00%\n",
      "Epoch 2/80 | Loss: 3.6700 | Val Acc: 3.23%\n",
      "Epoch 3/80 | Loss: 2.7532 | Val Acc: 8.06%\n",
      "Epoch 4/80 | Loss: 2.6525 | Val Acc: 9.68%\n",
      "Epoch 5/80 | Loss: 2.2770 | Val Acc: 6.45%\n",
      "Epoch 6/80 | Loss: 2.1918 | Val Acc: 6.45%\n",
      "Epoch 7/80 | Loss: 1.9604 | Val Acc: 8.06%\n",
      "Epoch 8/80 | Loss: 1.7941 | Val Acc: 8.06%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 39\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     36\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39mcorrect\u001b[38;5;241m/\u001b[39mtotal\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[69], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs)\u001b[0m\n\u001b[0;32m     15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     20\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mD:\\VUT\\Anaconda\\envs\\SUR\\lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\VUT\\Anaconda\\envs\\SUR\\lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\VUT\\Anaconda\\envs\\SUR\\lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = FaceCNN(num_classes=31).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "def train(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs} | Loss: {running_loss/len(train_loader):.4f} | '\n",
    "              f'Val Acc: {100*correct/total:.2f}%')\n",
    "\n",
    "# Start training\n",
    "train(epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0699dc67-51fb-4e3d-b441-f21b995aa3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 | Loss: 2.6679 | Val Acc: 41.94%\n",
      "Epoch 2/40 | Loss: 2.6585 | Val Acc: 37.10%\n",
      "Epoch 3/40 | Loss: 2.6186 | Val Acc: 37.10%\n",
      "Epoch 4/40 | Loss: 2.6161 | Val Acc: 33.87%\n",
      "Epoch 5/40 | Loss: 2.6004 | Val Acc: 38.71%\n",
      "Epoch 6/40 | Loss: 2.5821 | Val Acc: 45.16%\n",
      "Epoch 7/40 | Loss: 2.5701 | Val Acc: 40.32%\n",
      "Epoch 8/40 | Loss: 2.5617 | Val Acc: 38.71%\n",
      "Epoch 9/40 | Loss: 2.5595 | Val Acc: 41.94%\n",
      "Epoch 10/40 | Loss: 2.5537 | Val Acc: 40.32%\n",
      "Epoch 11/40 | Loss: 2.5575 | Val Acc: 40.32%\n",
      "Epoch 12/40 | Loss: 2.5574 | Val Acc: 40.32%\n",
      "Epoch 13/40 | Loss: 2.5367 | Val Acc: 38.71%\n",
      "Epoch 14/40 | Loss: 2.5230 | Val Acc: 45.16%\n",
      "Epoch 15/40 | Loss: 2.5266 | Val Acc: 48.39%\n",
      "Epoch 16/40 | Loss: 2.5227 | Val Acc: 45.16%\n",
      "Epoch 17/40 | Loss: 2.5227 | Val Acc: 46.77%\n",
      "Epoch 18/40 | Loss: 2.5227 | Val Acc: 46.77%\n",
      "Epoch 19/40 | Loss: 2.5226 | Val Acc: 46.77%\n",
      "Epoch 20/40 | Loss: 2.5226 | Val Acc: 46.77%\n",
      "Epoch 21/40 | Loss: 2.5251 | Val Acc: 43.55%\n",
      "Epoch 22/40 | Loss: 2.4937 | Val Acc: 41.94%\n",
      "Epoch 23/40 | Loss: 2.4971 | Val Acc: 33.87%\n",
      "Epoch 24/40 | Loss: 2.4932 | Val Acc: 40.32%\n",
      "Epoch 25/40 | Loss: 2.4917 | Val Acc: 38.71%\n",
      "Epoch 26/40 | Loss: 2.4905 | Val Acc: 38.71%\n",
      "Epoch 27/40 | Loss: 2.4905 | Val Acc: 38.71%\n",
      "Epoch 28/40 | Loss: 2.4905 | Val Acc: 38.71%\n",
      "Epoch 29/40 | Loss: 2.4905 | Val Acc: 38.71%\n",
      "Epoch 30/40 | Loss: 2.4905 | Val Acc: 38.71%\n",
      "Epoch 31/40 | Loss: 2.4905 | Val Acc: 38.71%\n",
      "Epoch 32/40 | Loss: 2.4905 | Val Acc: 38.71%\n",
      "Epoch 33/40 | Loss: 2.4905 | Val Acc: 38.71%\n",
      "Epoch 34/40 | Loss: 2.4905 | Val Acc: 38.71%\n",
      "Epoch 35/40 | Loss: 2.4905 | Val Acc: 38.71%\n",
      "Epoch 36/40 | Loss: 2.4905 | Val Acc: 38.71%\n",
      "Epoch 37/40 | Loss: 2.4904 | Val Acc: 37.10%\n",
      "Epoch 38/40 | Loss: 2.4892 | Val Acc: 38.71%\n",
      "Epoch 39/40 | Loss: 2.4892 | Val Acc: 38.71%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[52], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs)\u001b[0m\n\u001b[0;32m     12\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mD:\\VUT\\Anaconda\\envs\\SUR\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\VUT\\Anaconda\\envs\\SUR\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[49], line 48\u001b[0m, in \u001b[0;36mFaceCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     47\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(batch_size, \u001b[38;5;241m9248\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu3(x)\n\u001b[0;32m     50\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)\n",
      "File \u001b[1;32mD:\\VUT\\Anaconda\\envs\\SUR\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\VUT\\Anaconda\\envs\\SUR\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\VUT\\Anaconda\\envs\\SUR\\lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1665c9a2-8c12-400e-ae9c-ac02c0c45e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Loss: 0.6480 | Val Acc: 51.61%\n",
      "Epoch 2/20 | Loss: 0.5222 | Val Acc: 41.94%\n",
      "Epoch 3/20 | Loss: 0.5956 | Val Acc: 48.39%\n",
      "Epoch 4/20 | Loss: 0.6444 | Val Acc: 41.94%\n",
      "Epoch 5/20 | Loss: 0.5608 | Val Acc: 46.77%\n",
      "Epoch 6/20 | Loss: 0.5830 | Val Acc: 45.16%\n",
      "Epoch 7/20 | Loss: 0.6319 | Val Acc: 50.00%\n",
      "Epoch 8/20 | Loss: 0.5633 | Val Acc: 50.00%\n",
      "Epoch 9/20 | Loss: 0.5408 | Val Acc: 50.00%\n",
      "Epoch 10/20 | Loss: 0.6083 | Val Acc: 51.61%\n",
      "Epoch 11/20 | Loss: 0.5811 | Val Acc: 43.55%\n",
      "Epoch 12/20 | Loss: 0.5772 | Val Acc: 50.00%\n",
      "Epoch 13/20 | Loss: 0.5913 | Val Acc: 50.00%\n",
      "Epoch 14/20 | Loss: 0.5435 | Val Acc: 51.61%\n",
      "Epoch 15/20 | Loss: 0.5417 | Val Acc: 53.23%\n",
      "Epoch 16/20 | Loss: 0.5547 | Val Acc: 48.39%\n",
      "Epoch 17/20 | Loss: 0.6225 | Val Acc: 50.00%\n",
      "Epoch 18/20 | Loss: 0.6074 | Val Acc: 53.23%\n",
      "Epoch 19/20 | Loss: 0.5592 | Val Acc: 50.00%\n",
      "Epoch 20/20 | Loss: 0.5176 | Val Acc: 53.23%\n"
     ]
    }
   ],
   "source": [
    "train(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913fb6a1-6500-4d50-95de-d043f9e7670c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SUR",
   "language": "python",
   "name": "sur"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
